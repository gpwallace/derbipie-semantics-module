{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3191b436-bf86-47e4-b767-862460ddfbcd",
   "metadata": {},
   "source": [
    "# Italic Bibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f16690-4306-4c53-9d99-771928fc7727",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simplemma\n",
      "  Downloading simplemma-0.9.1-py3-none-any.whl (75.5 MB)\n",
      "                                              0.0/75.5 MB ? eta -:--:--\n",
      "                                              0.0/75.5 MB ? eta -:--:--\n",
      "                                             0.0/75.5 MB 393.8 kB/s eta 0:03:12\n",
      "                                             0.1/75.5 MB 901.1 kB/s eta 0:01:24\n",
      "                                              0.3/75.5 MB 1.5 MB/s eta 0:00:49\n",
      "                                              0.5/75.5 MB 2.3 MB/s eta 0:00:33\n",
      "                                              0.9/75.5 MB 3.3 MB/s eta 0:00:23\n",
      "                                              1.4/75.5 MB 4.5 MB/s eta 0:00:17\n",
      "     -                                        2.4/75.5 MB 6.7 MB/s eta 0:00:11\n",
      "     --                                       4.1/75.5 MB 10.0 MB/s eta 0:00:08\n",
      "     ---                                      6.0/75.5 MB 12.8 MB/s eta 0:00:06\n",
      "     ----                                     8.3/75.5 MB 16.5 MB/s eta 0:00:05\n",
      "     -----                                   10.4/75.5 MB 24.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     ------                                  12.4/75.5 MB 19.3 MB/s eta 0:00:04\n",
      "     -------                                 14.6/75.5 MB 20.5 MB/s eta 0:00:03\n",
      "     --------                                16.3/75.5 MB 19.9 MB/s eta 0:00:03\n",
      "     --------                                17.2/75.5 MB 18.7 MB/s eta 0:00:04\n",
      "     --------                                17.2/75.5 MB 18.7 MB/s eta 0:00:04\n",
      "     --------                                17.2/75.5 MB 18.7 MB/s eta 0:00:04\n",
      "     --------                                17.2/75.5 MB 18.7 MB/s eta 0:00:04\n",
      "     ----------                              19.7/75.5 MB 14.2 MB/s eta 0:00:04\n",
      "     ------------                            24.9/75.5 MB 31.2 MB/s eta 0:00:02\n",
      "     -------------                           27.1/75.5 MB 32.8 MB/s eta 0:00:02\n",
      "     --------------                          29.0/75.5 MB 65.6 MB/s eta 0:00:01\n",
      "     ---------------                         30.4/75.5 MB 65.6 MB/s eta 0:00:01\n",
      "     ----------------                        31.4/75.5 MB 46.7 MB/s eta 0:00:01\n",
      "     ----------------                        32.5/75.5 MB 40.9 MB/s eta 0:00:02\n",
      "     ----------------                        32.5/75.5 MB 40.9 MB/s eta 0:00:02\n",
      "     -----------------                       33.6/75.5 MB 29.8 MB/s eta 0:00:02\n",
      "     ------------------                      35.8/75.5 MB 28.5 MB/s eta 0:00:02\n",
      "     -------------------                     38.0/75.5 MB 29.7 MB/s eta 0:00:02\n",
      "     --------------------                    40.2/75.5 MB 29.7 MB/s eta 0:00:02\n",
      "     ---------------------                   42.2/75.5 MB 32.8 MB/s eta 0:00:02\n",
      "     ----------------------                  44.1/75.5 MB 43.7 MB/s eta 0:00:01\n",
      "     -----------------------                 46.4/75.5 MB 43.7 MB/s eta 0:00:01\n",
      "     ------------------------                48.2/75.5 MB 46.9 MB/s eta 0:00:01\n",
      "     -------------------------               48.5/75.5 MB 38.6 MB/s eta 0:00:01\n",
      "     --------------------------              50.6/75.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------             52.7/75.5 MB 38.5 MB/s eta 0:00:01\n",
      "     ----------------------------            54.8/75.5 MB 43.7 MB/s eta 0:00:01\n",
      "     -----------------------------           56.7/75.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------          58.8/75.5 MB 40.9 MB/s eta 0:00:01\n",
      "     -------------------------------         60.9/75.5 MB 43.7 MB/s eta 0:00:01\n",
      "     --------------------------------        63.0/75.5 MB 43.7 MB/s eta 0:00:01\n",
      "     ---------------------------------       64.0/75.5 MB 40.9 MB/s eta 0:00:01\n",
      "     ---------------------------------       64.8/75.5 MB 34.4 MB/s eta 0:00:01\n",
      "     ----------------------------------      66.6/75.5 MB 36.3 MB/s eta 0:00:01\n",
      "     -----------------------------------     68.6/75.5 MB 36.3 MB/s eta 0:00:01\n",
      "     ------------------------------------    70.5/75.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------    71.5/75.5 MB 31.2 MB/s eta 0:00:01\n",
      "     -------------------------------------   72.3/75.5 MB 31.1 MB/s eta 0:00:01\n",
      "     -------------------------------------   72.3/75.5 MB 31.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  74.1/75.5 MB 25.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  75.5/75.5 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  75.5/75.5 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  75.5/75.5 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  75.5/75.5 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 75.5/75.5 MB 19.3 MB/s eta 0:00:00\n",
      "Installing collected packages: simplemma\n",
      "Successfully installed simplemma-0.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install simplemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "84c86dce-b876-4b54-a54e-2dfa6e060d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "import simplemma\n",
    "import pandas as pd\n",
    "import ast\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0be5fc5e-26fe-4d1c-8481-73f52aea341e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_corpus(text):\n",
    "    sentences = sent_tokenize(text.replace(\"\\n\", \" \").lower())\n",
    "    tokenized_sentences = [\n",
    "        RegexpTokenizer(r\"\\w+\").tokenize(sentence)\n",
    "        for sentence in sentences\n",
    "    ]\n",
    "    tokenized_corpus = [\n",
    "        [word for word in sentence]\n",
    "        for sentence in tokenized_sentences\n",
    "    ]\n",
    "    return tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80580148-0981-4683-9869-0eeba95053a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contains_explicit_return(f):\n",
    "    return any(isinstance(node, ast.Return) for node in ast.walk(ast.parse(inspect.getsource(f))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57057841-af65-4b7a-a69c-147794943350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latin</th>\n",
       "      <th>spanish</th>\n",
       "      <th>french</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad</td>\n",
       "      <td>á</td>\n",
       "      <td>à</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>āla</td>\n",
       "      <td>ala</td>\n",
       "      <td>aile</td>\n",
       "      <td>ala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diaeta</td>\n",
       "      <td>dieta</td>\n",
       "      <td>diète</td>\n",
       "      <td>dieta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aenigma</td>\n",
       "      <td>enigma</td>\n",
       "      <td>ánigme</td>\n",
       "      <td>enigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aqua</td>\n",
       "      <td>agua</td>\n",
       "      <td>eau</td>\n",
       "      <td>acqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>attendo</td>\n",
       "      <td>atender</td>\n",
       "      <td>attendere</td>\n",
       "      <td>attendere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>attestor</td>\n",
       "      <td>atestar</td>\n",
       "      <td>attester</td>\n",
       "      <td>attestare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>vigilia</td>\n",
       "      <td>vela</td>\n",
       "      <td>éveiller</td>\n",
       "      <td>vedetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>arteria</td>\n",
       "      <td>arteria</td>\n",
       "      <td>artère</td>\n",
       "      <td>arteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>transverto</td>\n",
       "      <td>través</td>\n",
       "      <td>travers</td>\n",
       "      <td>attraverso</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          latin  spanish     french     italian\n",
       "0            ad       á         à           a\n",
       "1          āla      ala       aile         ala\n",
       "2        diaeta    dieta     diète       dieta\n",
       "3       aenigma   enigma    ánigme      enigma\n",
       "4          aqua     agua        eau       acqua\n",
       "..          ...      ...        ...         ...\n",
       "136     attendo  atender  attendere   attendere\n",
       "137    attestor  atestar   attester   attestare\n",
       "138     vigilia     vela  éveiller     vedetta\n",
       "139     arteria  arteria    artère     arteria\n",
       "140  transverto  través    travers  attraverso\n",
       "\n",
       "[141 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/bibles/cognates.csv', names=['latin', 'spanish', 'french', 'italian'], header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61244e71-2b7f-49de-a6d9-de0e9066fc42",
   "metadata": {},
   "source": [
    "## French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20d8b367-c602-4261-8d28-2b0394835fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/french/french_bible_processed.txt', 'w', encoding = 'utf-8') as f:\n",
    "    with open(\"texts/italic_bibles/french_bible.txt\", 'r') as g:\n",
    "        text = g.read()\n",
    "        tokens = word_tokenize(text)\n",
    "        stop = set(stopwords.words('french'))\n",
    "        for i in tokens:\n",
    "            f.write(simplemma.lemmatize(i, lang = 'fr') + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e65294b8-5f89-472f-ac9b-5fad292ef8f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/french/french_bible_processed.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    fr_corpus = tokenize_corpus(text)\n",
    "    fr_model = Word2Vec(sentences = fr_corpus, \n",
    "                 vector_size = 100, \n",
    "                 window = 20,\n",
    "                 epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5710edc0-406b-439b-ad3b-d7d4006b10b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_words = df['french']\n",
    "fr_index = list(fr_words)\n",
    "fr_vectors = {}\n",
    "for word in fr_words:\n",
    "    if word in fr_model.wv.index_to_key:\n",
    "        fr_vectors[fr_index.index(word)] = fr_model.wv.get_vector(word)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85caca5a-fe29-472e-94b1-c87a1082d797",
   "metadata": {},
   "source": [
    "### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a09ad0f-0985-4a1c-8fc3-6fb2d38e90e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/spanish/spanish_bible_processed.txt', 'w', encoding = 'utf-8') as f:\n",
    "    with open(\"texts/italic_bibles/spanish_bible.txt\", 'r') as g:\n",
    "        text = g.read()\n",
    "        tokens = word_tokenize(text)\n",
    "        stop = set(stopwords.words('spanish'))\n",
    "        for i in tokens:\n",
    "            f.write(simplemma.lemmatize(i, lang = 'es') + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "81bae4d8-b7fe-4ab7-a322-c448bb871413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/spanish/spanish_bible_processed.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    es_corpus = tokenize_corpus(text)\n",
    "    es_model = Word2Vec(sentences = es_corpus, \n",
    "                 vector_size = 100, \n",
    "                 window = 20,\n",
    "                 epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0bab7550-d6c3-4ada-b2ba-ad9b20a2d424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es_words = df['spanish']\n",
    "es_index = list(es_words)\n",
    "es_vectors = {}\n",
    "for word in es_words:\n",
    "    if word in es_model.wv.index_to_key:\n",
    "        es_vectors[es_index.index(word)] = es_model.wv.get_vector(word)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2caf3-d02f-4297-aa78-8bbe78902278",
   "metadata": {},
   "source": [
    "### Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97fd56a3-2e57-4659-8ff1-e6916f20eb3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/italian/italian_bible_processed.txt', 'w', encoding = 'utf-8') as f:\n",
    "    with open(\"texts/italic_bibles/italian_bible.txt\", 'r') as g:\n",
    "        text = g.read()\n",
    "        tokens = word_tokenize(text)\n",
    "        stop = set(stopwords.words('italian'))\n",
    "        for i in tokens:\n",
    "            f.write(simplemma.lemmatize(i, lang = 'it') + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ddfc0be5-162a-46e9-9918-b5dbb76f3a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/italian/italian_bible_processed.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    it_corpus = tokenize_corpus(text)\n",
    "    it_model = Word2Vec(sentences = it_corpus, \n",
    "                 vector_size = 100, \n",
    "                 window = 20,\n",
    "                 epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "02b52f2d-388e-4386-b110-2480f8df4000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "it_words = df['italian']\n",
    "it_index = list(it_words)\n",
    "it_vectors = {}\n",
    "for word in it_words:\n",
    "    if word in it_model.wv.index_to_key:\n",
    "        it_vectors[it_index.index(word)] = it_model.wv.get_vector(word)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b1cc7-9df7-417b-b7b7-b7facc729522",
   "metadata": {},
   "source": [
    "### Latin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9217726f-f4ee-47f8-81bb-cf5194d9747c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/latin/latin_bible_processed.txt', 'w', encoding = 'utf-8') as f:\n",
    "    with open(\"texts/italic_bibles/latin_bible.txt\", 'r') as g:\n",
    "        text = g.read()\n",
    "        tokens = word_tokenize(text)\n",
    "        for i in tokens:\n",
    "            f.write(simplemma.lemmatize(i, lang = 'la') + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "66097f06-4705-48f3-a8e9-d5a7a527adcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/latin/latin_bible_processed.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    la_corpus = tokenize_corpus(text)\n",
    "    la_model = Word2Vec(sentences = la_corpus, \n",
    "                 vector_size = 100, \n",
    "                 window = 20,\n",
    "                 epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "01cf1854-a8b6-4823-958b-354dd6553b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "la_words = df['latin']\n",
    "la_index = list(la_words)\n",
    "la_vectors = {}\n",
    "for word in la_words:\n",
    "    if word in la_model.wv.index_to_key:\n",
    "        la_vectors[la_index.index(word)] = la_model.wv.get_vector(word)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91acca-4748-40cf-88f8-44407746950a",
   "metadata": {},
   "source": [
    "### Comparing Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "da160670-0464-4206-b76e-d56dd46e5dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_dicts = [la_vectors, es_vectors, fr_vectors, it_vectors]\n",
    "\n",
    "organized_vectors = {k: [d[k] for d in vector_dicts if k in d.keys()] for k in vector_dicts[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e0b9c3e4-9399-4fbe-afd9-fac181259aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/vectors/vectors.txt', 'w', encoding = 'utf-8') as f:\n",
    "    f.write(str(organized_vectors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
