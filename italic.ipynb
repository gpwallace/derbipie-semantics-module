{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3191b436-bf86-47e4-b767-862460ddfbcd",
   "metadata": {},
   "source": [
    "# Italic Bibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f16690-4306-4c53-9d99-771928fc7727",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simplemma\n",
      "  Downloading simplemma-0.9.1-py3-none-any.whl (75.5 MB)\n",
      "                                              0.0/75.5 MB ? eta -:--:--\n",
      "                                              0.0/75.5 MB ? eta -:--:--\n",
      "                                             0.0/75.5 MB 393.8 kB/s eta 0:03:12\n",
      "                                             0.1/75.5 MB 901.1 kB/s eta 0:01:24\n",
      "                                              0.3/75.5 MB 1.5 MB/s eta 0:00:49\n",
      "                                              0.5/75.5 MB 2.3 MB/s eta 0:00:33\n",
      "                                              0.9/75.5 MB 3.3 MB/s eta 0:00:23\n",
      "                                              1.4/75.5 MB 4.5 MB/s eta 0:00:17\n",
      "     -                                        2.4/75.5 MB 6.7 MB/s eta 0:00:11\n",
      "     --                                       4.1/75.5 MB 10.0 MB/s eta 0:00:08\n",
      "     ---                                      6.0/75.5 MB 12.8 MB/s eta 0:00:06\n",
      "     ----                                     8.3/75.5 MB 16.5 MB/s eta 0:00:05\n",
      "     -----                                   10.4/75.5 MB 24.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     -----                                   10.5/75.5 MB 26.2 MB/s eta 0:00:03\n",
      "     ------                                  12.4/75.5 MB 19.3 MB/s eta 0:00:04\n",
      "     -------                                 14.6/75.5 MB 20.5 MB/s eta 0:00:03\n",
      "     --------                                16.3/75.5 MB 19.9 MB/s eta 0:00:03\n",
      "     --------                                17.2/75.5 MB 18.7 MB/s eta 0:00:04\n",
      "     --------                                17.2/75.5 MB 18.7 MB/s eta 0:00:04\n",
      "     --------                                17.2/75.5 MB 18.7 MB/s eta 0:00:04\n",
      "     --------                                17.2/75.5 MB 18.7 MB/s eta 0:00:04\n",
      "     ----------                              19.7/75.5 MB 14.2 MB/s eta 0:00:04\n",
      "     ------------                            24.9/75.5 MB 31.2 MB/s eta 0:00:02\n",
      "     -------------                           27.1/75.5 MB 32.8 MB/s eta 0:00:02\n",
      "     --------------                          29.0/75.5 MB 65.6 MB/s eta 0:00:01\n",
      "     ---------------                         30.4/75.5 MB 65.6 MB/s eta 0:00:01\n",
      "     ----------------                        31.4/75.5 MB 46.7 MB/s eta 0:00:01\n",
      "     ----------------                        32.5/75.5 MB 40.9 MB/s eta 0:00:02\n",
      "     ----------------                        32.5/75.5 MB 40.9 MB/s eta 0:00:02\n",
      "     -----------------                       33.6/75.5 MB 29.8 MB/s eta 0:00:02\n",
      "     ------------------                      35.8/75.5 MB 28.5 MB/s eta 0:00:02\n",
      "     -------------------                     38.0/75.5 MB 29.7 MB/s eta 0:00:02\n",
      "     --------------------                    40.2/75.5 MB 29.7 MB/s eta 0:00:02\n",
      "     ---------------------                   42.2/75.5 MB 32.8 MB/s eta 0:00:02\n",
      "     ----------------------                  44.1/75.5 MB 43.7 MB/s eta 0:00:01\n",
      "     -----------------------                 46.4/75.5 MB 43.7 MB/s eta 0:00:01\n",
      "     ------------------------                48.2/75.5 MB 46.9 MB/s eta 0:00:01\n",
      "     -------------------------               48.5/75.5 MB 38.6 MB/s eta 0:00:01\n",
      "     --------------------------              50.6/75.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------             52.7/75.5 MB 38.5 MB/s eta 0:00:01\n",
      "     ----------------------------            54.8/75.5 MB 43.7 MB/s eta 0:00:01\n",
      "     -----------------------------           56.7/75.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------          58.8/75.5 MB 40.9 MB/s eta 0:00:01\n",
      "     -------------------------------         60.9/75.5 MB 43.7 MB/s eta 0:00:01\n",
      "     --------------------------------        63.0/75.5 MB 43.7 MB/s eta 0:00:01\n",
      "     ---------------------------------       64.0/75.5 MB 40.9 MB/s eta 0:00:01\n",
      "     ---------------------------------       64.8/75.5 MB 34.4 MB/s eta 0:00:01\n",
      "     ----------------------------------      66.6/75.5 MB 36.3 MB/s eta 0:00:01\n",
      "     -----------------------------------     68.6/75.5 MB 36.3 MB/s eta 0:00:01\n",
      "     ------------------------------------    70.5/75.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------    71.5/75.5 MB 31.2 MB/s eta 0:00:01\n",
      "     -------------------------------------   72.3/75.5 MB 31.1 MB/s eta 0:00:01\n",
      "     -------------------------------------   72.3/75.5 MB 31.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  74.1/75.5 MB 25.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  75.5/75.5 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  75.5/75.5 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  75.5/75.5 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  75.5/75.5 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 75.5/75.5 MB 19.3 MB/s eta 0:00:00\n",
      "Installing collected packages: simplemma\n",
      "Successfully installed simplemma-0.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install simplemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84c86dce-b876-4b54-a54e-2dfa6e060d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "import simplemma\n",
    "import pandas as pd\n",
    "import ast\n",
    "import inspect\n",
    "import numpy as np\n",
    "import json\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be5fc5e-26fe-4d1c-8481-73f52aea341e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_corpus(text):\n",
    "    sentences = sent_tokenize(text.replace(\"\\n\", \" \").lower())\n",
    "    tokenized_sentences = [\n",
    "        RegexpTokenizer(r\"\\w+\").tokenize(sentence)\n",
    "        for sentence in sentences\n",
    "    ]\n",
    "    tokenized_corpus = [\n",
    "        [word for word in sentence]\n",
    "        for sentence in tokenized_sentences\n",
    "    ]\n",
    "    return tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd090b1e-5dc4-4655-be74-a9a0f04e6e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shared_vecs = np.array([4,6,8,13,14,15,18,22,27,28,38,40,49,54,55,57,60,65,67,69,71,72,74,75,79,81,82,83,89,90,91,93,94,97,102,104,105,110,112,114,118,119,122,129])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80580148-0981-4683-9869-0eeba95053a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contains_explicit_return(f):\n",
    "    return any(isinstance(node, ast.Return) for node in ast.walk(ast.parse(inspect.getsource(f))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57057841-af65-4b7a-a69c-147794943350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latin</th>\n",
       "      <th>spanish</th>\n",
       "      <th>french</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aqua</td>\n",
       "      <td>agua</td>\n",
       "      <td>eau</td>\n",
       "      <td>acqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alter</td>\n",
       "      <td>otro</td>\n",
       "      <td>autre</td>\n",
       "      <td>altro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ante</td>\n",
       "      <td>antes</td>\n",
       "      <td>avant</td>\n",
       "      <td>davanti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>arca</td>\n",
       "      <td>arca</td>\n",
       "      <td>arche</td>\n",
       "      <td>arca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>arcus</td>\n",
       "      <td>arco</td>\n",
       "      <td>arc</td>\n",
       "      <td>arco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ardor</td>\n",
       "      <td>ardor</td>\n",
       "      <td>ardeur</td>\n",
       "      <td>ardore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aurum</td>\n",
       "      <td>oro</td>\n",
       "      <td>or</td>\n",
       "      <td>oro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>barba</td>\n",
       "      <td>barba</td>\n",
       "      <td>barbe</td>\n",
       "      <td>barba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>folium</td>\n",
       "      <td>hoja</td>\n",
       "      <td>feuille</td>\n",
       "      <td>foglia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>flamma</td>\n",
       "      <td>llama</td>\n",
       "      <td>flamme</td>\n",
       "      <td>fiamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>frons</td>\n",
       "      <td>frente</td>\n",
       "      <td>front</td>\n",
       "      <td>fronte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>decem</td>\n",
       "      <td>diez</td>\n",
       "      <td>dix</td>\n",
       "      <td>dieci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>in</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>et</td>\n",
       "      <td>y</td>\n",
       "      <td>et</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>lac</td>\n",
       "      <td>leche</td>\n",
       "      <td>lait</td>\n",
       "      <td>latte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>homo</td>\n",
       "      <td>hombre</td>\n",
       "      <td>homme</td>\n",
       "      <td>uomo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>vivo</td>\n",
       "      <td>vivo</td>\n",
       "      <td>vif</td>\n",
       "      <td>vivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>canto</td>\n",
       "      <td>cantar</td>\n",
       "      <td>chanter</td>\n",
       "      <td>cantare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>capto</td>\n",
       "      <td>cazar</td>\n",
       "      <td>chasser</td>\n",
       "      <td>caccia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>caput</td>\n",
       "      <td>cabo</td>\n",
       "      <td>chef</td>\n",
       "      <td>capo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>color</td>\n",
       "      <td>color</td>\n",
       "      <td>couleur</td>\n",
       "      <td>colore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>credo</td>\n",
       "      <td>creer</td>\n",
       "      <td>croire</td>\n",
       "      <td>credere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>clavis</td>\n",
       "      <td>llave</td>\n",
       "      <td>clef</td>\n",
       "      <td>chiave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>contra</td>\n",
       "      <td>contra</td>\n",
       "      <td>contre</td>\n",
       "      <td>contro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>lectus</td>\n",
       "      <td>lecho</td>\n",
       "      <td>lit</td>\n",
       "      <td>letto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>laus</td>\n",
       "      <td>loar</td>\n",
       "      <td>louer</td>\n",
       "      <td>lodare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>forma</td>\n",
       "      <td>horma</td>\n",
       "      <td>forme</td>\n",
       "      <td>forma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>morior</td>\n",
       "      <td>morir</td>\n",
       "      <td>mourir</td>\n",
       "      <td>morire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>niger</td>\n",
       "      <td>negro</td>\n",
       "      <td>noir</td>\n",
       "      <td>nero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>nox</td>\n",
       "      <td>noche</td>\n",
       "      <td>nuit</td>\n",
       "      <td>notte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>novus</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>neuf</td>\n",
       "      <td>nuovo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>oculus</td>\n",
       "      <td>ojo</td>\n",
       "      <td>œil</td>\n",
       "      <td>occhio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>operarius</td>\n",
       "      <td>obrero</td>\n",
       "      <td>ouvrier</td>\n",
       "      <td>operaio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>auris</td>\n",
       "      <td>oreja</td>\n",
       "      <td>oreille</td>\n",
       "      <td>orecchio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>palea</td>\n",
       "      <td>paja</td>\n",
       "      <td>paille</td>\n",
       "      <td>paglia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>probo</td>\n",
       "      <td>probar</td>\n",
       "      <td>prouver</td>\n",
       "      <td>provare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>petra</td>\n",
       "      <td>piedra</td>\n",
       "      <td>pierre</td>\n",
       "      <td>pietra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>pluo</td>\n",
       "      <td>llover</td>\n",
       "      <td>pleuvoir</td>\n",
       "      <td>piovere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>possum</td>\n",
       "      <td>poder</td>\n",
       "      <td>pouvoir</td>\n",
       "      <td>potere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>rota</td>\n",
       "      <td>rueda</td>\n",
       "      <td>roue</td>\n",
       "      <td>ruota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>sanus</td>\n",
       "      <td>sano</td>\n",
       "      <td>sain</td>\n",
       "      <td>sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>sapio</td>\n",
       "      <td>saber</td>\n",
       "      <td>savoir</td>\n",
       "      <td>sapere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>consilium</td>\n",
       "      <td>consejo</td>\n",
       "      <td>conseil</td>\n",
       "      <td>consiglio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>salus</td>\n",
       "      <td>salud</td>\n",
       "      <td>salut</td>\n",
       "      <td>salute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         latin  spanish    french    italian\n",
       "4         aqua     agua       eau      acqua\n",
       "6        alter     otro     autre      altro\n",
       "8         ante    antes     avant    davanti\n",
       "13        arca     arca     arche       arca\n",
       "14       arcus     arco       arc       arco\n",
       "15       ardor    ardor    ardeur     ardore\n",
       "18       aurum      oro        or        oro\n",
       "22       barba    barba     barbe      barba\n",
       "27      folium     hoja   feuille     foglia\n",
       "28      flamma    llama    flamme     fiamma\n",
       "38       frons   frente     front     fronte\n",
       "40       decem     diez       dix      dieci\n",
       "49          in       en        en         in\n",
       "54          et        y        et          e\n",
       "55         lac    leche      lait      latte\n",
       "57        homo   hombre     homme       uomo\n",
       "60        vivo     vivo       vif       vivo\n",
       "65       canto   cantar   chanter    cantare\n",
       "67       capto    cazar   chasser     caccia\n",
       "69       caput     cabo      chef       capo\n",
       "71       color    color   couleur     colore\n",
       "72       credo    creer    croire    credere\n",
       "74      clavis    llave      clef     chiave\n",
       "75      contra   contra    contre     contro\n",
       "79      lectus    lecho       lit      letto\n",
       "81        laus     loar     louer     lodare\n",
       "82       forma    horma     forme      forma\n",
       "83      morior    morir    mourir     morire\n",
       "89       niger    negro      noir       nero\n",
       "90         nox    noche      nuit      notte\n",
       "91       novus    nuevo      neuf      nuovo\n",
       "93      oculus      ojo       œil     occhio\n",
       "94   operarius   obrero   ouvrier    operaio\n",
       "97       auris    oreja   oreille   orecchio\n",
       "102      palea     paja    paille     paglia\n",
       "104      probo   probar   prouver    provare\n",
       "105      petra   piedra    pierre     pietra\n",
       "110       pluo   llover  pleuvoir    piovere\n",
       "112     possum    poder   pouvoir     potere\n",
       "114       rota    rueda      roue      ruota\n",
       "118      sanus     sano      sain       sano\n",
       "119      sapio    saber    savoir     sapere\n",
       "122  consilium  consejo   conseil  consiglio\n",
       "129      salus    salud     salut     salute"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/bibles/cognates.csv', names=['latin', 'spanish', 'french', 'italian'], header=None)\n",
    "df = df.loc[[4,6,8,13,14,15,18,22,27,28,38,40,49,54,55,57,60,65,67,69,71,72,74,75,79,81,82,83,89,90,91,93,94,97,102,104,105,110,112,114,118,119,122,129]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61244e71-2b7f-49de-a6d9-de0e9066fc42",
   "metadata": {},
   "source": [
    "## French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20d8b367-c602-4261-8d28-2b0394835fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/french/french_bible_processed.txt', 'w', encoding = 'utf-8') as f:\n",
    "    with open(\"texts/italic_bibles/french_bible.txt\", 'r') as g:\n",
    "        text = g.read()\n",
    "        tokens = word_tokenize(text)\n",
    "        stop = set(stopwords.words('french'))\n",
    "        for i in tokens:\n",
    "            f.write(simplemma.lemmatize(i, lang = 'fr') + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65294b8-5f89-472f-ac9b-5fad292ef8f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/french/french_bible_processed.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    fr_corpus = tokenize_corpus(text)\n",
    "    fr_model = Word2Vec(sentences = fr_corpus, \n",
    "                 vector_size = 100, \n",
    "                 window = 20,\n",
    "                 epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5710edc0-406b-439b-ad3b-d7d4006b10b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_words = df['french']\n",
    "fr_index = list(fr_words)\n",
    "fr_vectors = {}\n",
    "for word in fr_words:\n",
    "    if word in fr_model.wv.index_to_key:\n",
    "        fr_vectors[fr_index.index(word)] = fr_model.wv.get_vector(word)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa307527-5d87-4838-ae91-9ab5696c5371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_cosines = {}\n",
    "fr_wordbox = []\n",
    "for word1 in fr_words:\n",
    "    for word2 in fr_words:\n",
    "        if word2 not in fr_wordbox:\n",
    "            if word1 != word2:\n",
    "                similarity = fr_model.wv.similarity(word1, word2)\n",
    "                fr_cosines[(word1, word2)] = similarity\n",
    "                fr_wordbox.append(word1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85caca5a-fe29-472e-94b1-c87a1082d797",
   "metadata": {},
   "source": [
    "### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a09ad0f-0985-4a1c-8fc3-6fb2d38e90e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/spanish/spanish_bible_processed.txt', 'w', encoding = 'utf-8') as f:\n",
    "    with open(\"texts/italic_bibles/spanish_bible.txt\", 'r') as g:\n",
    "        text = g.read()\n",
    "        tokens = word_tokenize(text)\n",
    "        stop = set(stopwords.words('spanish'))\n",
    "        for i in tokens:\n",
    "            f.write(simplemma.lemmatize(i, lang = 'es') + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81bae4d8-b7fe-4ab7-a322-c448bb871413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/spanish/spanish_bible_processed.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    es_corpus = tokenize_corpus(text)\n",
    "    es_model = Word2Vec(sentences = es_corpus, \n",
    "                 vector_size = 100, \n",
    "                 window = 20,\n",
    "                 epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bab7550-d6c3-4ada-b2ba-ad9b20a2d424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es_words = df['spanish']\n",
    "es_index = list(es_words)\n",
    "es_vectors = {}\n",
    "for word in es_words:\n",
    "    if word in es_model.wv.index_to_key:\n",
    "        es_vectors[es_index.index(word)] = es_model.wv.get_vector(word)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2dd2405-2f43-4e48-81d8-3e0f5e5df0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es_cosines = {}\n",
    "es_wordbox = []\n",
    "for word1 in es_words:\n",
    "    for word2 in es_words:\n",
    "        if word2 not in es_wordbox:\n",
    "            if word1 != word2:\n",
    "                similarity = es_model.wv.similarity(word1, word2)\n",
    "                es_cosines[(word1, word2)] = similarity\n",
    "                es_wordbox.append(word1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2caf3-d02f-4297-aa78-8bbe78902278",
   "metadata": {},
   "source": [
    "### Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97fd56a3-2e57-4659-8ff1-e6916f20eb3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/italian/italian_bible_processed.txt', 'w', encoding = 'utf-8') as f:\n",
    "    with open(\"texts/italic_bibles/italian_bible.txt\", 'r') as g:\n",
    "        text = g.read()\n",
    "        tokens = word_tokenize(text)\n",
    "        stop = set(stopwords.words('italian'))\n",
    "        for i in tokens:\n",
    "            f.write(simplemma.lemmatize(i, lang = 'it') + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddfc0be5-162a-46e9-9918-b5dbb76f3a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/italian/italian_bible_processed.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    it_corpus = tokenize_corpus(text)\n",
    "    it_model = Word2Vec(sentences = it_corpus, \n",
    "                 vector_size = 100, \n",
    "                 window = 20,\n",
    "                 epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02b52f2d-388e-4386-b110-2480f8df4000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "it_words = df['italian']\n",
    "it_index = list(it_words)\n",
    "it_vectors = {}\n",
    "for word in it_words:\n",
    "    if word in it_model.wv.index_to_key:\n",
    "        it_vectors[it_index.index(word)] = it_model.wv.get_vector(word)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ca891be-f56a-4831-9874-e44e34b6cf61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "it_cosines = {}\n",
    "it_wordbox = []\n",
    "for word1 in it_words:\n",
    "    for word2 in it_words:\n",
    "        if word2 not in it_wordbox:\n",
    "            if word1 != word2:\n",
    "                similarity = it_model.wv.similarity(word1, word2)\n",
    "                it_cosines[(word1, word2)] = similarity\n",
    "                it_wordbox.append(word1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b1cc7-9df7-417b-b7b7-b7facc729522",
   "metadata": {},
   "source": [
    "### Latin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9217726f-f4ee-47f8-81bb-cf5194d9747c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/latin/latin_bible_processed.txt', 'w', encoding = 'utf-8') as f:\n",
    "    with open(\"texts/italic_bibles/latin_bible.txt\", 'r') as g:\n",
    "        text = g.read()\n",
    "        tokens = word_tokenize(text)\n",
    "        for i in tokens:\n",
    "            f.write(simplemma.lemmatize(i, lang = 'la') + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66097f06-4705-48f3-a8e9-d5a7a527adcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/latin/latin_bible_processed.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    la_corpus = tokenize_corpus(text)\n",
    "    la_model = Word2Vec(sentences = la_corpus, \n",
    "                 vector_size = 100, \n",
    "                 window = 20,\n",
    "                 epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01cf1854-a8b6-4823-958b-354dd6553b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "la_words = df['latin']\n",
    "la_index = list(la_words)\n",
    "la_vectors = {}\n",
    "for word in la_words:\n",
    "    if word in la_model.wv.index_to_key:\n",
    "        la_vectors[la_index.index(word)] = la_model.wv.get_vector(word)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80ec7f88-fddc-47e3-a101-0649fd0c34ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "la_cosines = {}\n",
    "la_wordbox = []\n",
    "for word1 in la_words:\n",
    "    for word2 in la_words:\n",
    "        if word2 not in la_wordbox:\n",
    "            if word1 != word2:\n",
    "                similarity = la_model.wv.similarity(word1, word2)\n",
    "                la_cosines[(word1, word2)] = similarity\n",
    "                la_wordbox.append(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1aa2c46b-fab9-41cb-b547-2cbf00633a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "la_dict = {'la_dict': la_cosines}\n",
    "fr_dict = {'fr_dict': fr_cosines}\n",
    "es_dict = {'es_dict': es_cosines}\n",
    "it_dict = {'it_dict': it_cosines}\n",
    "with open(\"data/bibles/vectors/cosines.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(str(f\"Latin:\\n{la_dict}\\n\\nFrench:\\n{fr_dict}\\n\\nSpanish:\\n{es_dict}\\n\\nItalian:\\n{it_dict}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91acca-4748-40cf-88f8-44407746950a",
   "metadata": {},
   "source": [
    "### Comparing Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bce513a0-3e5a-4e87-82de-3c7b1c59976e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values = list(range(141))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "319ba157-c8c5-4dc3-b637-297b999421d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for word in fr_index:\n",
    "    fr_dict = { k:v for (k,v) in zip(values, fr_index)}\n",
    "for word in es_index:\n",
    "    es_dict = { k:v for (k,v) in zip(values, es_index)}\n",
    "for word in it_index:\n",
    "    it_dict = { k:v for (k,v) in zip(values, it_index)}\n",
    "for word in la_index:\n",
    "    la_dict = { k:v for (k,v) in zip(values, la_index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efa8835b-0691-4aa7-8e5d-eb203e6f5791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_dict_true = {}\n",
    "for k, v in fr_dict.items():\n",
    "    if v in fr_model.wv.index_to_key:\n",
    "        fr_dict_true[k] = 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a68314f5-7169-49b0-ba7c-ae10fd8373f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es_dict_true = {}\n",
    "for k, v in es_dict.items():\n",
    "    if v in es_model.wv.index_to_key:\n",
    "        es_dict_true[k] = 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edc4c963-8813-4712-8d3d-79c647f2db89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "it_dict_true = {}\n",
    "for k, v in it_dict.items():\n",
    "    if v in it_model.wv.index_to_key:\n",
    "        it_dict_true[k] = 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afb17132-b56f-463c-9564-94e06c1f299c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "la_dict_true = {}\n",
    "for k, v in la_dict.items():\n",
    "    if v in la_model.wv.index_to_key:\n",
    "        la_dict_true[k] = 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8814df46-ccd9-4a96-96c0-9bf8ad57f7e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({(0, 'T'),\n",
       "            (1, 'T'),\n",
       "            (2, 'T'),\n",
       "            (3, 'T'),\n",
       "            (4, 'T'),\n",
       "            (5, 'T'),\n",
       "            (6, 'T'),\n",
       "            (7, 'T'),\n",
       "            (8, 'T'),\n",
       "            (9, 'T'),\n",
       "            (10, 'T'),\n",
       "            (11, 'T'),\n",
       "            (12, 'T'),\n",
       "            (13, 'T'),\n",
       "            (14, 'T'),\n",
       "            (15, 'T'),\n",
       "            (16, 'T'),\n",
       "            (17, 'T'),\n",
       "            (18, 'T'),\n",
       "            (19, 'T'),\n",
       "            (20, 'T'),\n",
       "            (21, 'T'),\n",
       "            (22, 'T'),\n",
       "            (23, 'T'),\n",
       "            (24, 'T'),\n",
       "            (25, 'T'),\n",
       "            (26, 'T'),\n",
       "            (27, 'T'),\n",
       "            (28, 'T'),\n",
       "            (29, 'T'),\n",
       "            (30, 'T'),\n",
       "            (31, 'T'),\n",
       "            (32, 'T'),\n",
       "            (33, 'T'),\n",
       "            (34, 'T'),\n",
       "            (35, 'T'),\n",
       "            (36, 'T'),\n",
       "            (37, 'T'),\n",
       "            (38, 'T'),\n",
       "            (39, 'T'),\n",
       "            (40, 'T'),\n",
       "            (41, 'T'),\n",
       "            (42, 'T'),\n",
       "            (43, 'T')})}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_key = frozenset(fr_dict_true.items())\n",
    "es_key = frozenset(es_dict_true.items())\n",
    "it_key = frozenset(it_dict_true.items())\n",
    "la_key = frozenset(la_dict_true.items())\n",
    "t_f_cognates = {la_key, es_key, fr_key, it_key}\n",
    "t_f_cognates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da160670-0464-4206-b76e-d56dd46e5dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_dicts = [la_vectors, es_vectors, fr_vectors, it_vectors]\n",
    "\n",
    "organized_vectors = {k: [d[k] for d in vector_dicts if k in d.keys()] for k in vector_dicts[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0b9c3e4-9399-4fbe-afd9-fac181259aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/bibles/vectors/vectors.txt', 'w', encoding = 'utf-8') as f:\n",
    "    f.write(str(organized_vectors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
